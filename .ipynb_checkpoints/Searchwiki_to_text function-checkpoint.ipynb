{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://wikipedia.readthedocs.io/en/latest/code.html#api\n",
    "#https://wikipedia.readthedocs.io/en/latest/quickstart.html\n",
    "\n",
    "# this is a basic function to get ideas of page title from wikipedia for a particular keyword. we created a \n",
    "# a function allowing to type it faster, and just specyfing the keyword.\n",
    "\n",
    "import wikipedia\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# This functions works exactly the same way as searchwiki_to_csv. being the main difference that instead\n",
    "# of introducing the resulting files in the csv storage directory, with csv format, it does it with txt. files in\n",
    "# the text storage directory. This causes a different aproach to be taken at the end of the code. \n",
    "\n",
    "# once again its arguments are stringtosearch , the keyword for wich it will return wikipedia pages, \n",
    "# number of results is the number of pages we want to get the data from related to the keyword.\n",
    "#slanguage is the language you want wikipedia to search on, \n",
    "# and ircreated is a boolean argument, used to specified if you have done this search before or not. We recommend\n",
    "# refering to 'Searchwiki_to_csv function' file to read further detail into the characteristics of this function \n",
    "# and its arguments.\n",
    "\n",
    "\n",
    "def searchwiki_to_text(stringtosearch,number_of_results = 10,slanguage = 'en',dircreated = False):\n",
    "\n",
    "    wikipedia.set_lang(slanguage)\n",
    "    path = '/home/dataguy/wikiapp1/searchwiki_to_text_storage_folder/' + stringtosearch + \"_dir/\"\n",
    "    if dircreated == False :\n",
    "        os.mkdir(path)\n",
    "    elif dircreated == True :\n",
    "        pass\n",
    "    \n",
    "    searchobject = wikipedia.search(stringtosearch, results=number_of_results, suggestion=False)\n",
    "      \n",
    "    for i in searchobject :\n",
    "        try :\n",
    "            objectpage = wikipedia.page(title=i, pageid=None, auto_suggest=False, redirect=False, preload=False)\n",
    "        except wikipedia.exceptions.DisambiguationError as e :\n",
    "            print(\"the search object \" + i + \" is not recognized by wikipedia as a true\\\n",
    "            title for this language in its search engine, thus, it was skipped , \\\n",
    "            try changing to a language that might recognize it or finding the real title to capture its data\")\n",
    "            \n",
    "            continue\n",
    "            \n",
    "        # Here is one of the main differences between this function and the searchwiki_to_csv function. \n",
    "        #The string content object of the pages of each instance of the loop, are not divided in instances of a \n",
    "        #list, instead they are all introduced as a unique string in the txt file. Also the file object \n",
    "        # can be created with the open() function isntead of .to_csv from pandas library. \n",
    "            \n",
    "        contentobjectpage = objectpage.content\n",
    "        contentobjectpageasstring = str(contentobjectpage)\n",
    "        \n",
    " \n",
    "        name_of_file = str(i)\n",
    "        completeName = path + name_of_file + \".txt\"\n",
    "        File_object = open(file =completeName,mode = 'w')\n",
    "        File_object.write(contentobjectpageasstring)\n",
    "        File_object.close()\n",
    "        \n",
    "\n",
    "\n",
    "# We did not want to explain all the sintax of the code once again, as many parts are used the same\n",
    "# as 'Searchwiki_to_csv function' , once again, we recommend you to check this function out first if\n",
    "# you are having trouble understanding the code. In that file everything is explained line by line. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the search object ROPA is not recognized by wikipedia as a true            title for this language in its search engine, thus, it was skipped ,             try changing to a language that might recognize it or finding the real title to capture its data\n"
     ]
    }
   ],
   "source": [
    "# example of the code being executed\n",
    "\n",
    "searchwiki_to_text(\"ropa\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
