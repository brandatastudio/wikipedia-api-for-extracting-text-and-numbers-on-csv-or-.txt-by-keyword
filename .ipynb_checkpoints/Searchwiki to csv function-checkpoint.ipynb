{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://wikipedia.readthedocs.io/en/latest/code.html#api\n",
    "#https://wikipedia.readthedocs.io/en/latest/quickstart.html\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# this function, based on a keyword, gathers all the sentences on a number of resulting  articles obtained\n",
    "# on the wikipedia for said keyword, and places them inside a csv file . One csv file for each resulting page\n",
    "# all in one directory. \n",
    "\n",
    "#Arguments that uses: stringtosearch is the keyword for wich it will return wikipedia pages, \n",
    "# number of results is the number of pages we want to get the data from related to the keyword. The more results\n",
    "# we ask for, obviously the search ets wider giving more info but with lesser pertinence.\n",
    "#slanguage is the language you want wikipedia to search on, its based on its regular expressions for language.\n",
    "# dircreated is a boolean argument, used to specified if you have done this search before or not, this function\n",
    "# takes care of creating a directory to store all the csvs, so if its a second time you are calling for the same\n",
    "# keyword, and you have not deleted the previously created directory it will return an error. Thus, this argument\n",
    "# if true, it will work exactly as it should but using the already created directory ( instead of creating it from)\n",
    "# scratch, to place the csvs.\n",
    "\n",
    "# Libraries used:\n",
    "import wikipedia\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# if its your first time using this function, its very important to change the 'path' variable inside this\n",
    "# code, to adjust to your path, specifically the parts before /wikiapp1/ because in your case, you might be working\n",
    "# from a directory different from home, and with a different user name. \n",
    "\n",
    "\n",
    "\n",
    "def searchwiki_to_csv(stringtosearch,number_of_results = 10,slanguage = 'en',dircreated = False):\n",
    "    # So the first thing we do, is specify a language, this can be changed when calling the function.\n",
    "    # You have to use wikipedia `s regular expressions for languages when using it. \n",
    "    # We prepare the directory in which we will place our created csvs, a path we will be calling also when\n",
    "    # inserting the data later on in this function. \n",
    "    # with searchobject, we create a search  for a particular keyword(stringtosearch), basically its a \n",
    "    # list object with a number of keywords that turn from wikipedias search engine, as the most likely to be \n",
    "    # titles of wikipedia articles related to string to search. \n",
    "    \n",
    "    wikipedia.set_lang(slanguage)\n",
    "    \n",
    "    #IMPORTANT: make sure to adapt this path to your path\n",
    "    path = '/home/dataguy/wikiapp1/searchwiki_to_csv_storage_folder/' + stringtosearch + \"_dir/\"\n",
    "    \n",
    "    if dircreated == False :\n",
    "        os.mkdir(path)\n",
    "    elif dircreated == True :\n",
    "        pass\n",
    "    \n",
    "    searchobject = wikipedia.search(stringtosearch, results=number_of_results, suggestion=False)\n",
    "    \n",
    "    # now, for each of those instances in searchobject we are going to process the data, first we will\n",
    "    # create an objectpage that represents the wikipedia page of each article. We will add an exception for disambigfuation\n",
    "    # error, when the title is not recognized as so in the search engine for that language and returns a disambiguation\n",
    "    # page instead. \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    for i in searchobject :\n",
    "        try : \n",
    "            objectpage = wikipedia.page(title=i, pageid=None, auto_suggest=False, redirect=False, preload=False)\n",
    "        except wikipedia.exceptions.DisambiguationError as e :\n",
    "            print(\"the search object \" + i + \" is not recognized by wikipedia as a true\\\n",
    "            title for this language in its search engine, thus, it was skipped , \\\n",
    "            try changing to a language that might recognize it or finding the real title to capture its data\")\n",
    "            \n",
    "            continue\n",
    "            \n",
    "        # continuing the loop, after obtaining the objectpage, we will create an object representing its content\n",
    "        #, we will convert it to a string, just to make the code more robust\n",
    "        # we will transform all the sentences in the content to instances of a list, creating a list with all the \n",
    "        # sentences in the wikipedia page. \n",
    "                \n",
    "        contentobjectpage = objectpage.content\n",
    "        contentobjectpageasstring = str(contentobjectpage)\n",
    "        objectsentenceslist= re.split('[.!?]',contentobjectpageasstring)\n",
    "        \n",
    "        \n",
    "         #  now we prepare to place this list in our csv, by converting it to a panda dataframe\n",
    "        objectdf = pd.DataFrame({str(i) : np.array(objectsentenceslist)})\n",
    "        \n",
    "        \n",
    "        # finally, we create the file object, in this case it will be one for each instance of the for loop, \n",
    "        # and we introduce the datafrmae inside. \n",
    "        \n",
    "        name_of_file = str(i)\n",
    "        completename = path + name_of_file + \".csv\"\n",
    "        objectdf.to_csv(completename)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the search object Manuel is not recognized by wikipedia as a true            title for this language in its search engine, thus, it was skipped ,             try changing to a language that might recognize it or finding the real title to capture its data\n"
     ]
    }
   ],
   "source": [
    "# some  example calls\n",
    "        \n",
    "searchwiki_to_csv(\"manuel\",10,'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
